{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f94335b-673d-44ba-b630-f68587a70062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6627372-1971-4dbf-a55b-33b7e33386e1",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76606bd3-e182-469e-96b6-aef736209f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_touse, df_predict = pickle.load(open('datasets.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0a07b5c-f6a1-4987-8914-4dfec544427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_touse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ddd55b-072a-4560-88af-96cf156d7957",
   "metadata": {},
   "source": [
    "## Splitting dataset and storing descriptive statsitics and indices of splits to process whole dataframe to prevent data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13dba180-4a2e-41ed-95ed-c3147365c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df.columns.tolist()\n",
    "predictors.remove(\"target\")\n",
    "X = df[predictors]\n",
    "y = df[\"target\"]\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "458b2ca9-3f3f-48ca-88e5-2ba3706a14cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index_values = X_test.index.values\n",
    "train_index_values = Y_train.index.values\n",
    "\n",
    "\n",
    "# Select only the numerical columns\n",
    "numeric_cols = X_train.select_dtypes(include=['int', 'float'])\n",
    "\n",
    "# Compute the mean of each numerical column\n",
    "X_train_mean = numeric_cols.mean()\n",
    "X_test_mean = numeric_cols.mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compute the mean of each numerical column\n",
    "Y_train_mean = Y_train.mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compute the mean of each numerical column\n",
    "Y_test_mean = Y_test.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3edfe0d-c1ca-4b55-bb1b-1b891dd1e499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3153aee8-52d7-4370-9e04-d0ebcd3d3c23",
   "metadata": {},
   "source": [
    "# Transform data\n",
    "## numerical NaNs replaced by Mean of respective split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "31552e82-39f2-48db-8ae6-783ba4225ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['insee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f941668c-811d-4a33-a796-63540ca75b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[train_index_values, ['PERSON_ID', 'AGE_2018', 'PAY', 'Working_hours']] = df.loc[train_index_values, ['PERSON_ID', 'AGE_2018', 'PAY', 'Working_hours']].fillna(X_train_mean)\n",
    "\n",
    "df.loc[test_index_values, ['PERSON_ID', 'AGE_2018', 'PAY', 'Working_hours']] = df.loc[test_index_values, ['PERSON_ID', 'AGE_2018', 'PAY', 'Working_hours']].fillna(X_test_mean)\n",
    "\n",
    "df.loc[train_index_values, ['target']] = df.loc[train_index_values, ['target']].fillna(Y_train_mean)\n",
    "\n",
    "df.loc[test_index_values, ['target']] = df.loc[test_index_values, ['target']].fillna(Y_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9723b5-b28f-4387-af54-ee5ab6873e54",
   "metadata": {},
   "source": [
    "## categorical NaNs replaced by random category of variable while respecting proportions of respective split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dcc6edd9-9843-4d0f-bece-6b62c13c5794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select only the categorical columns\n",
    "cat_cols = df.select_dtypes(include=['object'])\n",
    "\n",
    "## For the training set\n",
    "\n",
    "# Iterate over the categorical columns\n",
    "for col_name in cat_cols.columns:\n",
    "    # Select the column\n",
    "    col = X_train[col_name]\n",
    "    \n",
    "    # Compute the proportions of the categories\n",
    "    counts = col.value_counts(normalize=True)\n",
    "    \n",
    "    # Replace the NaN values with random categories\n",
    "    for i in col.index:\n",
    "        if pd.isnull(col[i]):\n",
    "            col[i] = random.choices(counts.index, counts.values)[0]\n",
    "            \n",
    "df.update(col)\n",
    "\n",
    "\n",
    "## For the test set\n",
    "\n",
    "for col_name in cat_cols.columns:\n",
    "    # Select the column\n",
    "    col = X_test[col_name]\n",
    "    \n",
    "    # Compute the proportions of the categories\n",
    "    counts = col.value_counts(normalize=True)\n",
    "    \n",
    "    # Replace the NaN values with random categories\n",
    "    for i in col.index:\n",
    "        if pd.isnull(col[i]):\n",
    "            col[i] = random.choices(counts.index, counts.values)[0]\n",
    "            \n",
    "df.update(col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f27250-ac3a-4772-b23f-d9da79afda0b",
   "metadata": {},
   "source": [
    "## One Hot Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68fc2e5d-4d59-478c-bb39-9825c92b5784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "## For the Train set\n",
    "\n",
    "# Select the string columns\n",
    "string_columns = df.select_dtypes(['object']).columns\n",
    "\n",
    "# Create a OneHotEncoder object\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit the encoder to the string columns\n",
    "encoder.fit(df[string_columns])\n",
    "\n",
    "# Encode the string columns\n",
    "encoded_data = encoder.transform(df[string_columns])\n",
    "\n",
    "# Create a DataFrame with the encoded columns and the original index\n",
    "encoded_df = pd.DataFrame(encoded_data.toarray(), index=df.index, columns=encoder.get_feature_names(string_columns))\n",
    "\n",
    "# Concatenate the encoded columns with the rest of the data\n",
    "df = pd.concat([encoded_df, df.drop(string_columns, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db8c489-b8c8-41ac-bfb5-f0ddbec5f93a",
   "metadata": {},
   "source": [
    "## Reassign processed splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2c505a11-e6e9-44b2-9d07-d619708a4cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.loc[train_index_values]\n",
    "X_train = X_train.drop('target', axis=1)\n",
    "X_test =  df.loc[test_index_values]\n",
    "X_test = X_test.drop('target', axis=1)\n",
    "Y_train = df.loc[train_index_values]['target']\n",
    "Y_test = df.loc[test_index_values]['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fc75c4-1876-405d-99c4-9c3b793903b2",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d444d6c7-d2cd-475d-b4de-85bcd7a8e847",
   "metadata": {},
   "source": [
    "## DecisionTree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f41246b5-6620-4879-93a5-008b4b66f82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5642934130439852\n",
      "{'min_samples_split': 95}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "dt_params = {'min_samples_split': [2, 5] + list(range(10, 100, 5))}\n",
    "\n",
    "#,\n",
    "#              'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "#              'min_impurity_decrease': [0.0, 0.1, 0.2, 0.3]}\n",
    "\n",
    "\n",
    "#dt_params = {'min_samples_split': [2, 5] + list(range(10, 250,5))} \n",
    "dt = DecisionTreeRegressor(random_state=0)\n",
    "cv_folds = KFold(5, shuffle=True, random_state=0)\n",
    "dt_cv = GridSearchCV(dt, dt_params, cv=cv_folds, n_jobs=-1) \n",
    "dt_cv.fit(X_train, Y_train) \n",
    "print(dt_cv.best_score_)\n",
    "print(dt_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4c3dea24-1ec8-4e70-ba43-7a45a4dd7e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 6.49\n",
      "Mean squared error: 71.88\n",
      "Root mean squared error: 8.48\n",
      "R-squared score: 0.58\n",
      "Adjusted R-squared score: 0.54\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import math\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_dt = dt_cv.predict(X_test)\n",
    "\n",
    "# Compute the mean absolute error\n",
    "mae = mean_absolute_error(Y_test, predictions_dt)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(Y_test, predicpredictions_dttions)\n",
    "\n",
    "# Compute the root mean squared error\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "# Compute the R-squared score\n",
    "r2 = r2_score(Y_test, predictions_dt)\n",
    "\n",
    "# Compute the adjusted R-squared score\n",
    "n = len(Y_test)\n",
    "p = X_test.shape[1]  # number of features\n",
    "adj_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Mean absolute error: {:.2f}\".format(mae))\n",
    "print(\"Mean squared error: {:.2f}\".format(mse))\n",
    "print(\"Root mean squared error: {:.2f}\".format(rmse))\n",
    "print(\"R-squared score: {:.2f}\".format(r2))\n",
    "print(\"Adjusted R-squared score: {:.2f}\".format(adj_r2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ec9fb9-ae9e-4391-bef0-0d4932bb91ee",
   "metadata": {},
   "source": [
    "## GradientBoosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "07d864d3-8280-465f-858c-7827c6f27a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6957355354397229\n",
      "{'learning_rate': 0.2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {'learning_rate': [0.2,0.1, 0.05, 0.01, 0.001]}\n",
    "\n",
    "\n",
    "# Create the gradient boosting model\n",
    "gb = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "# Create the K-fold cross-validation object\n",
    "cv_folds = KFold(5, shuffle=True, random_state=0)\n",
    "\n",
    "# Create the grid search object\n",
    "gb_cv = GridSearchCV(gb, param_grid, cv=cv_folds, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "gb_cv.fit(X_train, Y_train)\n",
    "\n",
    "print(gb_cv.best_score_)\n",
    "print(gb_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4e054e4b-ad92-4acd-aade-08b084eb5a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 5.55\n",
      "Mean squared error: 49.87\n",
      "Root mean squared error: 7.06\n",
      "R-squared score: 0.71\n",
      "Adjusted R-squared score: 0.68\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions_gb = gb_cv.predict(X_test)\n",
    "\n",
    "# Compute the mean absolute error\n",
    "mae = mean_absolute_error(Y_test, predictions_gb)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(Y_test, predictions_gb)\n",
    "\n",
    "# Compute the root mean squared error\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "# Compute the R-squared score\n",
    "r2 = r2_score(Y_test, predictions_gb)\n",
    "\n",
    "# Compute the adjusted R-squared score\n",
    "n = len(Y_test)\n",
    "p = X_test.shape[1]  # number of features\n",
    "adj_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Mean absolute error: {:.2f}\".format(mae))\n",
    "print(\"Mean squared error: {:.2f}\".format(mse))\n",
    "print(\"Root mean squared error: {:.2f}\".format(rmse))\n",
    "print(\"R-squared score: {:.2f}\".format(r2))\n",
    "print(\"Adjusted R-squared score: {:.2f}\".format(adj_r2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62375add-cac3-46fa-ac21-b56607abd8e5",
   "metadata": {},
   "source": [
    "## Ridge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0be4da86-e6bd-4fcc-ae78-1705d92c912d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6123357258856378\n",
      "{'alpha': 15.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {'alpha': [0.1, 1.0, 10.0, 15.0, 100.0, 1000.0]}\n",
    "              #,'max_iter': [100, 1000, 10000, 100000]}\n",
    "\n",
    "# Create the ridge regression model\n",
    "ridge = Ridge(random_state=0)\n",
    "\n",
    "# Create the K-fold cross-validation object\n",
    "cv_folds = KFold(5, shuffle=True, random_state=0)\n",
    "\n",
    "# Create the grid search object\n",
    "ridge_cv = GridSearchCV(ridge, param_grid, cv=cv_folds, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "ridge_cv.fit(X_train, Y_train)\n",
    "print(ridge_cv.best_score_)\n",
    "print(ridge_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "032c13af-8877-4cc1-8e46-9d57fd1d0bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 6.39\n",
      "Mean squared error: 64.56\n",
      "Root mean squared error: 8.04\n",
      "R-squared score: 0.62\n",
      "Adjusted R-squared score: 0.59\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import math\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_ridge = ridge_cv.predict(X_test)\n",
    "\n",
    "# Compute the mean absolute error\n",
    "mae = mean_absolute_error(Y_test, predictions_ridge)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(Y_test, predictions_ridge)\n",
    "\n",
    "# Compute the root mean squared error\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "# Compute the R-squared score\n",
    "r2 = r2_score(Y_test, predictions_ridge)\n",
    "\n",
    "# Compute the adjusted R-squared score\n",
    "n = len(Y_test)\n",
    "p = X_test.shape[1]  # number of features\n",
    "adj_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Mean absolute error: {:.2f}\".format(mae))\n",
    "print(\"Mean squared error: {:.2f}\".format(mse))\n",
    "print(\"Root mean squared error: {:.2f}\".format(rmse))\n",
    "print(\"R-squared score: {:.2f}\".format(r2))\n",
    "print(\"Adjusted R-squared score: {:.2f}\".format(adj_r2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439047b9-42d0-45c9-a9c5-72ab6004b074",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff7dd7d-e7d1-4125-b06b-b4fb1b976555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {'n_estimators': [5,7,10]}\n",
    "              #'max_depth': [2, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "              #'min_samples_split': [2, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "              #'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "\n",
    "# Create the random forest model\n",
    "rf = RandomForestRegressor(random_state=0)\n",
    "\n",
    "# Create the K-fold cross-validation object\n",
    "cv_folds = KFold(5, shuffle=True, random_state=0)\n",
    "\n",
    "# Create the grid search object\n",
    "rf_cv = GridSearchCV(rf, param_grid, cv=cv_folds, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "rf_cv.fit(X_train, Y_train)\n",
    "print(rf_cv.best_score_)\n",
    "print(rf_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6447177f-3663-4e5b-a71c-cb040a630c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc391649-5316-4d1e-a687-d82beadb7827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import math\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = rf_cv.predict(X_test)\n",
    "\n",
    "# Compute the mean absolute error\n",
    "mae = mean_absolute_error(Y_test, predictions)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(Y_test, predictions)\n",
    "\n",
    "# Compute the root mean squared error\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "# Compute the R-squared score\n",
    "r2 = r2_score(Y_test, predictions)\n",
    "\n",
    "# Compute the adjusted R-squared score\n",
    "n = len(Y_test)\n",
    "p = X_test.shape[1]  # number of features\n",
    "adj_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Mean absolute error: {:.2f}\".format(mae))\n",
    "print(\"Mean squared error: {:.2f}\".format(mse))\n",
    "print(\"Root mean squared error: {:.2f}\".format(rmse))\n",
    "print(\"R-squared score: {:.2f}\".format(r2))\n",
    "print(\"Adjusted R-squared score: {:.2f}\".format(adj_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10151329-1800-4239-9206-dab91a30ac19",
   "metadata": {},
   "source": [
    "## LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "40e579d9-bcb6-44a9-a835-48a0694624f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.748e+05, tolerance: 5.430e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.297e+04, tolerance: 5.499e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.702e+05, tolerance: 5.479e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.060e+04, tolerance: 5.475e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.380e+05, tolerance: 5.427e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.701e+05, tolerance: 5.430e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.807e+05, tolerance: 5.499e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.833e+05, tolerance: 5.479e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.021e+06, tolerance: 5.475e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.892e+05, tolerance: 5.427e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6125471487834089\n",
      "{'alpha': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.272e+05, tolerance: 6.827e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {'alpha': [0.005, 0.001, 0.00005]}\n",
    "              #,'max_iter': [100, 1000, 10000, 100000]}\n",
    "\n",
    "# Create the Lasso regression model\n",
    "lasso = Lasso(random_state=0)\n",
    "\n",
    "# Create the K-fold cross-validation object\n",
    "cv_folds = KFold(5, shuffle=True, random_state=0)\n",
    "\n",
    "# Create the grid search object\n",
    "lasso_cv = GridSearchCV(lasso, param_grid, cv=cv_folds, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "lasso_cv.fit(X_train, Y_train)\n",
    "print(lasso_cv.best_score_)\n",
    "print(lasso_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a5c2be41-720b-4518-83dd-ba4ec7e2adbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 6.40\n",
      "Mean squared error: 64.55\n",
      "Root mean squared error: 8.03\n",
      "R-squared score: 0.62\n",
      "Adjusted R-squared score: 0.59\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import math\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_lasso = lasso_cv.predict(X_test)\n",
    "\n",
    "# Compute the mean absolute error\n",
    "mae = mean_absolute_error(Y_test, predictions_lasso)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(Y_test, predictions_lasso)\n",
    "\n",
    "# Compute the root mean squared error\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "# Compute the R-squared score\n",
    "r2 = r2_score(Y_test, predictions_lasso)\n",
    "\n",
    "# Compute the adjusted R-squared score\n",
    "n = len(Y_test)\n",
    "p = X_test.shape[1]  # number of features\n",
    "adj_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Mean absolute error: {:.2f}\".format(mae))\n",
    "print(\"Mean squared error: {:.2f}\".format(mse))\n",
    "print(\"Root mean squared error: {:.2f}\".format(rmse))\n",
    "print(\"R-squared score: {:.2f}\".format(r2))\n",
    "print(\"Adjusted R-squared score: {:.2f}\".format(adj_r2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
