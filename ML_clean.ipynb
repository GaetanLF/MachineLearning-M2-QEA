{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f94335b-673d-44ba-b630-f68587a70062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import jupytext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6627372-1971-4dbf-a55b-33b7e33386e1",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "76606bd3-e182-469e-96b6-aef736209f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_touse, df_predict = pickle.load(open('datasets.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f0a07b5c-f6a1-4987-8914-4dfec544427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we just choose which dataset we want to handle\n",
    "df = df_touse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ddd55b-072a-4560-88af-96cf156d7957",
   "metadata": {},
   "source": [
    "## Splitting dataset and storing descriptive statsitics and indices of splits to process whole dataframe to prevent data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "13dba180-4a2e-41ed-95ed-c3147365c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df.columns.tolist()\n",
    "predictors.remove(\"target\")\n",
    "X = df[predictors]\n",
    "y = df[\"target\"]\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "458b2ca9-3f3f-48ca-88e5-2ba3706a14cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index_values = X_test.index.values\n",
    "train_index_values = Y_train.index.values\n",
    "\n",
    "\n",
    "\n",
    "# Select only the numerical columns\n",
    "numeric_cols = X_train.select_dtypes(include=['int', 'float'])\n",
    "\n",
    "# Compute the mean of each numerical column\n",
    "X_train_mean = numeric_cols.mean()\n",
    "X_test_mean = numeric_cols.mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compute the mean of each numerical column\n",
    "Y_train_mean = Y_train.mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compute the mean of each numerical column\n",
    "Y_test_mean = Y_test.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3153aee8-52d7-4370-9e04-d0ebcd3d3c23",
   "metadata": {},
   "source": [
    "# Transform data\n",
    "## numerical NaNs replaced by Mean of respective split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "31552e82-39f2-48db-8ae6-783ba4225ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['insee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f941668c-811d-4a33-a796-63540ca75b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[train_index_values, ['PERSON_ID', 'AGE_2018', 'PAY', 'Working_hours']] = df.loc[train_index_values, ['PERSON_ID', 'AGE_2018', 'PAY', 'Working_hours']].fillna(X_train_mean)\n",
    "\n",
    "df.loc[test_index_values, ['PERSON_ID', 'AGE_2018', 'PAY', 'Working_hours']] = df.loc[test_index_values, ['PERSON_ID', 'AGE_2018', 'PAY', 'Working_hours']].fillna(X_test_mean)\n",
    "\n",
    "df.loc[train_index_values, ['target']] = df.loc[train_index_values, ['target']].fillna(Y_train_mean)\n",
    "\n",
    "df.loc[test_index_values, ['target']] = df.loc[test_index_values, ['target']].fillna(Y_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9723b5-b28f-4387-af54-ee5ab6873e54",
   "metadata": {},
   "source": [
    "## categorical NaNs replaced by random category of variable while respecting proportions of respective split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dcc6edd9-9843-4d0f-bece-6b62c13c5794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/3862709179.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select only the categorical columns\n",
    "cat_cols = df.select_dtypes(include=['object'])\n",
    "\n",
    "## For the training set\n",
    "\n",
    "# Iterate over the categorical columns\n",
    "for col_name in cat_cols.columns:\n",
    "    # Select the column\n",
    "    col = X_train[col_name]\n",
    "    \n",
    "    # Compute the proportions of the categories\n",
    "    counts = col.value_counts(normalize=True)\n",
    "    \n",
    "    # Replace the NaN values with random categories\n",
    "    for i in col.index:\n",
    "        if pd.isnull(col[i]):\n",
    "            col[i] = random.choices(counts.index, counts.values)[0]\n",
    "            \n",
    "df.update(col)\n",
    "\n",
    "\n",
    "## For the test set\n",
    "\n",
    "for col_name in cat_cols.columns:\n",
    "    # Select the column\n",
    "    col = X_test[col_name]\n",
    "    \n",
    "    # Compute the proportions of the categories\n",
    "    counts = col.value_counts(normalize=True)\n",
    "    \n",
    "    # Replace the NaN values with random categories\n",
    "    for i in col.index:\n",
    "        if pd.isnull(col[i]):\n",
    "            col[i] = random.choices(counts.index, counts.values)[0]\n",
    "            \n",
    "df.update(col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f27250-ac3a-4772-b23f-d9da79afda0b",
   "metadata": {},
   "source": [
    "## One Hot Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "68fc2e5d-4d59-478c-bb39-9825c92b5784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Select the string columns\n",
    "string_columns = df.select_dtypes(['object']).columns\n",
    "\n",
    "# Create a OneHotEncoder object\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit the encoder to the string columns\n",
    "encoder.fit(df[string_columns])\n",
    "\n",
    "# Encode the string columns\n",
    "encoded_data = encoder.transform(df[string_columns])\n",
    "\n",
    "# Create a DataFrame with the encoded columns and the original index\n",
    "encoded_df = pd.DataFrame(encoded_data.toarray(), index=df.index, columns=encoder.get_feature_names(string_columns))\n",
    "\n",
    "# Concatenate the encoded columns with the rest of the data\n",
    "df = pd.concat([encoded_df, df.drop(string_columns, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ef76cd9a-6fce-4853-ab5b-2c1b177723c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERSON_ID</th>\n",
       "      <th>Job_42</th>\n",
       "      <th>SEX</th>\n",
       "      <th>IS_STUDENT</th>\n",
       "      <th>household_type</th>\n",
       "      <th>AGE_2018</th>\n",
       "      <th>activity_type</th>\n",
       "      <th>Highest_diploma</th>\n",
       "      <th>target</th>\n",
       "      <th>Emp_contract</th>\n",
       "      <th>...</th>\n",
       "      <th>Employee_count</th>\n",
       "      <th>contract_type</th>\n",
       "      <th>work_condition</th>\n",
       "      <th>job_category</th>\n",
       "      <th>ECONOMIC_SECTOR</th>\n",
       "      <th>PAY</th>\n",
       "      <th>Work_description</th>\n",
       "      <th>Company_category</th>\n",
       "      <th>Working_hours</th>\n",
       "      <th>job_dep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>csp_7_8</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>TYPEMR_4_4</td>\n",
       "      <td>75</td>\n",
       "      <td>act-2-1</td>\n",
       "      <td>EDUC1.1</td>\n",
       "      <td>82.3589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22903.688936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1507.053651</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>csp_8_6</td>\n",
       "      <td>Female</td>\n",
       "      <td>False</td>\n",
       "      <td>TYPEMR_1_2</td>\n",
       "      <td>95</td>\n",
       "      <td>act-2-1</td>\n",
       "      <td>EDUC1</td>\n",
       "      <td>81.6192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22903.688936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1507.053651</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>csp_3_1</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>TYPEMR_4_1</td>\n",
       "      <td>63</td>\n",
       "      <td>act-1-1</td>\n",
       "      <td>EDUC1.8</td>\n",
       "      <td>58.3912</td>\n",
       "      <td>TEMP|2|2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22903.688936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1507.053651</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>csp_5_2</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>TYPEMR_4_1</td>\n",
       "      <td>48</td>\n",
       "      <td>act-1-1</td>\n",
       "      <td>EDUC1.3</td>\n",
       "      <td>83.6962</td>\n",
       "      <td>TEMP|1|6</td>\n",
       "      <td>...</td>\n",
       "      <td>tr_4</td>\n",
       "      <td>CDI</td>\n",
       "      <td>C</td>\n",
       "      <td>O</td>\n",
       "      <td>QB</td>\n",
       "      <td>27531.000000</td>\n",
       "      <td>525d</td>\n",
       "      <td>ct_8</td>\n",
       "      <td>1805.000000</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>csp_4_7</td>\n",
       "      <td>Female</td>\n",
       "      <td>True</td>\n",
       "      <td>TYPEMR_1_2</td>\n",
       "      <td>30</td>\n",
       "      <td>act-1-1</td>\n",
       "      <td>EDUC1.8</td>\n",
       "      <td>44.1194</td>\n",
       "      <td>TEMP|1|1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22903.688936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1507.053651</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PERSON_ID   Job_42     SEX  IS_STUDENT household_type  AGE_2018  \\\n",
       "0          1  csp_7_8    Male       False     TYPEMR_4_4        75   \n",
       "1          2  csp_8_6  Female       False     TYPEMR_1_2        95   \n",
       "2          3  csp_3_1    Male       False     TYPEMR_4_1        63   \n",
       "3          6  csp_5_2    Male       False     TYPEMR_4_1        48   \n",
       "4         11  csp_4_7  Female        True     TYPEMR_1_2        30   \n",
       "\n",
       "  activity_type Highest_diploma   target Emp_contract  ... Employee_count  \\\n",
       "0       act-2-1         EDUC1.1  82.3589          NaN  ...            NaN   \n",
       "1       act-2-1           EDUC1  81.6192          NaN  ...            NaN   \n",
       "2       act-1-1         EDUC1.8  58.3912     TEMP|2|2  ...            NaN   \n",
       "3       act-1-1         EDUC1.3  83.6962     TEMP|1|6  ...           tr_4   \n",
       "4       act-1-1         EDUC1.8  44.1194     TEMP|1|1  ...            NaN   \n",
       "\n",
       "  contract_type work_condition job_category ECONOMIC_SECTOR           PAY  \\\n",
       "0           NaN            NaN          NaN             NaN  22903.688936   \n",
       "1           NaN            NaN          NaN             NaN  22903.688936   \n",
       "2           NaN            NaN          NaN             NaN  22903.688936   \n",
       "3           CDI              C            O              QB  27531.000000   \n",
       "4           NaN            NaN          NaN             NaN  22903.688936   \n",
       "\n",
       "   Work_description Company_category Working_hours  job_dep  \n",
       "0               NaN              NaN   1507.053651       29  \n",
       "1               NaN              NaN   1507.053651       15  \n",
       "2               NaN              NaN   1507.053651       35  \n",
       "3              525d             ct_8   1805.000000       69  \n",
       "4               NaN              NaN   1507.053651       92  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db8c489-b8c8-41ac-bfb5-f0ddbec5f93a",
   "metadata": {},
   "source": [
    "## Reassign processed splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2c505a11-e6e9-44b2-9d07-d619708a4cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train = df.loc[train_index_values]\n",
    "X_train = X_train.drop('target', axis=1)\n",
    "X_test =  df.loc[test_index_values]\n",
    "X_test = X_test.drop('target', axis=1)\n",
    "Y_train = df.loc[train_index_values]['target']\n",
    "Y_test = df.loc[test_index_values]['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fc75c4-1876-405d-99c4-9c3b793903b2",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d444d6c7-d2cd-475d-b4de-85bcd7a8e847",
   "metadata": {},
   "source": [
    "## DecisionTree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f41246b5-6620-4879-93a5-008b4b66f82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5642934130439852\n",
      "{'min_samples_split': 95}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "dt_params = {'min_samples_split': [2, 5] + list(range(10, 100, 5))}\n",
    "\n",
    "#,\n",
    "#              'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "#              'min_impurity_decrease': [0.0, 0.1, 0.2, 0.3]}\n",
    "\n",
    "\n",
    "#dt_params = {'min_samples_split': [2, 5] + list(range(10, 250,5))} \n",
    "dt = DecisionTreeRegressor(random_state=0)\n",
    "cv_folds = KFold(5, shuffle=True, random_state=0)\n",
    "dt_cv = GridSearchCV(dt, dt_params, cv=cv_folds, n_jobs=-1) \n",
    "dt_cv.fit(X_train, Y_train) \n",
    "print(dt_cv.best_score_)\n",
    "print(dt_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4c3dea24-1ec8-4e70-ba43-7a45a4dd7e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 6.49\n",
      "Mean squared error: 71.88\n",
      "Root mean squared error: 8.48\n",
      "R-squared score: 0.58\n",
      "Adjusted R-squared score: 0.54\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import math\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_dt = dt_cv.predict(X_test)\n",
    "\n",
    "# Compute the mean absolute error\n",
    "mae = mean_absolute_error(Y_test, predictions_dt)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(Y_test, predicpredictions_dttions)\n",
    "\n",
    "# Compute the root mean squared error\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "# Compute the R-squared score\n",
    "r2 = r2_score(Y_test, predictions_dt)\n",
    "\n",
    "# Compute the adjusted R-squared score\n",
    "n = len(Y_test)\n",
    "p = X_test.shape[1]  # number of features\n",
    "adj_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Mean absolute error: {:.2f}\".format(mae))\n",
    "print(\"Mean squared error: {:.2f}\".format(mse))\n",
    "print(\"Root mean squared error: {:.2f}\".format(rmse))\n",
    "print(\"R-squared score: {:.2f}\".format(r2))\n",
    "print(\"Adjusted R-squared score: {:.2f}\".format(adj_r2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ec9fb9-ae9e-4391-bef0-0d4932bb91ee",
   "metadata": {},
   "source": [
    "## GradientBoosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "07d864d3-8280-465f-858c-7827c6f27a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6957355354397229\n",
      "{'learning_rate': 0.2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {'learning_rate': [0.2,0.1, 0.05, 0.01, 0.001]}\n",
    "\n",
    "\n",
    "# Create the gradient boosting model\n",
    "gb = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "# Create the K-fold cross-validation object\n",
    "cv_folds = KFold(5, shuffle=True, random_state=0)\n",
    "\n",
    "# Create the grid search object\n",
    "gb_cv = GridSearchCV(gb, param_grid, cv=cv_folds, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "gb_cv.fit(X_train, Y_train)\n",
    "\n",
    "print(gb_cv.best_score_)\n",
    "print(gb_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4e054e4b-ad92-4acd-aade-08b084eb5a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 5.55\n",
      "Mean squared error: 49.87\n",
      "Root mean squared error: 7.06\n",
      "R-squared score: 0.71\n",
      "Adjusted R-squared score: 0.68\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions_gb = gb_cv.predict(X_test)\n",
    "\n",
    "# Compute the mean absolute error\n",
    "mae = mean_absolute_error(Y_test, predictions_gb)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(Y_test, predictions_gb)\n",
    "\n",
    "# Compute the root mean squared error\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "# Compute the R-squared score\n",
    "r2 = r2_score(Y_test, predictions_gb)\n",
    "\n",
    "# Compute the adjusted R-squared score\n",
    "n = len(Y_test)\n",
    "p = X_test.shape[1]  # number of features\n",
    "adj_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Mean absolute error: {:.2f}\".format(mae))\n",
    "print(\"Mean squared error: {:.2f}\".format(mse))\n",
    "print(\"Root mean squared error: {:.2f}\".format(rmse))\n",
    "print(\"R-squared score: {:.2f}\".format(r2))\n",
    "print(\"Adjusted R-squared score: {:.2f}\".format(adj_r2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c0da7da5-c2ae-4274-a448-f061ac400f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([83.77926288, 89.20391342, 85.46882248, ..., 78.64540132,\n",
       "       89.85832526, 64.43011106])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62375add-cac3-46fa-ac21-b56607abd8e5",
   "metadata": {},
   "source": [
    "## Ridge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0be4da86-e6bd-4fcc-ae78-1705d92c912d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6123357258856378\n",
      "{'alpha': 15.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {'alpha': [0.1, 1.0, 10.0, 15.0, 100.0, 1000.0]}\n",
    "              #,'max_iter': [100, 1000, 10000, 100000]}\n",
    "\n",
    "# Create the ridge regression model\n",
    "ridge = Ridge(random_state=0)\n",
    "\n",
    "# Create the K-fold cross-validation object\n",
    "cv_folds = KFold(5, shuffle=True, random_state=0)\n",
    "\n",
    "# Create the grid search object\n",
    "ridge_cv = GridSearchCV(ridge, param_grid, cv=cv_folds, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "ridge_cv.fit(X_train, Y_train)\n",
    "print(ridge_cv.best_score_)\n",
    "print(ridge_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "032c13af-8877-4cc1-8e46-9d57fd1d0bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 6.39\n",
      "Mean squared error: 64.56\n",
      "Root mean squared error: 8.04\n",
      "R-squared score: 0.62\n",
      "Adjusted R-squared score: 0.59\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import math\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_ridge = ridge_cv.predict(X_test)\n",
    "\n",
    "# Compute the mean absolute error\n",
    "mae = mean_absolute_error(Y_test, predictions_ridge)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(Y_test, predictions_ridge)\n",
    "\n",
    "# Compute the root mean squared error\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "# Compute the R-squared score\n",
    "r2 = r2_score(Y_test, predictions_ridge)\n",
    "\n",
    "# Compute the adjusted R-squared score\n",
    "n = len(Y_test)\n",
    "p = X_test.shape[1]  # number of features\n",
    "adj_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Mean absolute error: {:.2f}\".format(mae))\n",
    "print(\"Mean squared error: {:.2f}\".format(mse))\n",
    "print(\"Root mean squared error: {:.2f}\".format(rmse))\n",
    "print(\"R-squared score: {:.2f}\".format(r2))\n",
    "print(\"Adjusted R-squared score: {:.2f}\".format(adj_r2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439047b9-42d0-45c9-a9c5-72ab6004b074",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7ff7dd7d-e7d1-4125-b06b-b4fb1b976555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6541091528632353\n",
      "{'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {'n_estimators': [5,7,10]}\n",
    "              #'max_depth': [2, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "              #'min_samples_split': [2, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "              #'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "\n",
    "# Create the random forest model\n",
    "rf = RandomForestRegressor(random_state=0)\n",
    "\n",
    "# Create the K-fold cross-validation object\n",
    "cv_folds = KFold(5, shuffle=True, random_state=0)\n",
    "\n",
    "# Create the grid search object\n",
    "rf_cv = GridSearchCV(rf, param_grid, cv=cv_folds, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "rf_cv.fit(X_train, Y_train)\n",
    "print(rf_cv.best_score_)\n",
    "print(rf_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bc391649-5316-4d1e-a687-d82beadb7827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 5.79\n",
      "Mean squared error: 56.49\n",
      "Root mean squared error: 7.52\n",
      "R-squared score: 0.67\n",
      "Adjusted R-squared score: 0.64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import math\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_rf = rf_cv.predict(X_test)\n",
    "\n",
    "# Compute the mean absolute error\n",
    "mae = mean_absolute_error(Y_test, predictions_rf)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(Y_test, predictions_rf)\n",
    "\n",
    "# Compute the root mean squared error\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "# Compute the R-squared score\n",
    "r2 = r2_score(Y_test, predictions_rf)\n",
    "\n",
    "# Compute the adjusted R-squared score\n",
    "n = len(Y_test)\n",
    "p = X_test.shape[1]  # number of features\n",
    "adj_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Mean absolute error: {:.2f}\".format(mae))\n",
    "print(\"Mean squared error: {:.2f}\".format(mse))\n",
    "print(\"Root mean squared error: {:.2f}\".format(rmse))\n",
    "print(\"R-squared score: {:.2f}\".format(r2))\n",
    "print(\"Adjusted R-squared score: {:.2f}\".format(adj_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10151329-1800-4239-9206-dab91a30ac19",
   "metadata": {},
   "source": [
    "## LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "40e579d9-bcb6-44a9-a835-48a0694624f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.748e+05, tolerance: 5.430e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.297e+04, tolerance: 5.499e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.702e+05, tolerance: 5.479e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.060e+04, tolerance: 5.475e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.380e+05, tolerance: 5.427e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.701e+05, tolerance: 5.430e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.807e+05, tolerance: 5.499e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.833e+05, tolerance: 5.479e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.021e+06, tolerance: 5.475e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.892e+05, tolerance: 5.427e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6125471487834089\n",
      "{'alpha': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jan-philippkretschmann/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.272e+05, tolerance: 6.827e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {'alpha': [0.005, 0.001, 0.00005]}\n",
    "              #,'max_iter': [100, 1000, 10000, 100000]}\n",
    "\n",
    "# Create the Lasso regression model\n",
    "lasso = Lasso(random_state=0)\n",
    "\n",
    "# Create the K-fold cross-validation object\n",
    "cv_folds = KFold(5, shuffle=True, random_state=0)\n",
    "\n",
    "# Create the grid search object\n",
    "lasso_cv = GridSearchCV(lasso, param_grid, cv=cv_folds, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "lasso_cv.fit(X_train, Y_train)\n",
    "print(lasso_cv.best_score_)\n",
    "print(lasso_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a5c2be41-720b-4518-83dd-ba4ec7e2adbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 6.40\n",
      "Mean squared error: 64.55\n",
      "Root mean squared error: 8.03\n",
      "R-squared score: 0.62\n",
      "Adjusted R-squared score: 0.59\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import math\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_lasso = lasso_cv.predict(X_test)\n",
    "\n",
    "# Compute the mean absolute error\n",
    "mae = mean_absolute_error(Y_test, predictions_lasso)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(Y_test, predictions_lasso)\n",
    "\n",
    "# Compute the root mean squared error\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "# Compute the R-squared score\n",
    "r2 = r2_score(Y_test, predictions_lasso)\n",
    "\n",
    "# Compute the adjusted R-squared score\n",
    "n = len(Y_test)\n",
    "p = X_test.shape[1]  # number of features\n",
    "adj_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Mean absolute error: {:.2f}\".format(mae))\n",
    "print(\"Mean squared error: {:.2f}\".format(mse))\n",
    "print(\"Root mean squared error: {:.2f}\".format(rmse))\n",
    "print(\"R-squared score: {:.2f}\".format(r2))\n",
    "print(\"Adjusted R-squared score: {:.2f}\".format(adj_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bbaa58-6b9c-4143-b229-7028de2ed0e9",
   "metadata": {},
   "source": [
    "## Gradient boosting applied to df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f5a9c4-fe87-4aec-8a94-72d3b9b6c948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_931/2434735091.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_931/2434735091.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_931/2434735091.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_931/2434735091.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_931/2434735091.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n"
     ]
    }
   ],
   "source": [
    "df_touse, df_predict = pickle.load(open('datasets.sav','rb'))\n",
    "\n",
    "# Transform data\n",
    "df = df_predict\n",
    "df_predict = df_predict.drop(columns=['insee'])\n",
    "\n",
    "### numerical NaNs replaced by Mean\n",
    "\n",
    "\n",
    "## for the df_touse or train set\n",
    "# Select only the numerical columns\n",
    "numeric_cols = df_touse.select_dtypes(include=['int', 'float'])\n",
    "\n",
    "# Compute the mean of each numerical column\n",
    "means = numeric_cols.mean()\n",
    "\n",
    "# Replace NaN values with the median of each column\n",
    "df_touse[numeric_cols.columns] = numeric_cols.fillna(means)\n",
    "\n",
    "\n",
    "## for the df_predict set\n",
    "# Select only the numerical columns\n",
    "numeric_cols = df_predict.select_dtypes(include=['int', 'float'])\n",
    "\n",
    "# Compute the mean of each numerical column\n",
    "means = numeric_cols.mean()\n",
    "\n",
    "# Replace NaN values with the median of each column\n",
    "df_predict[numeric_cols.columns] = numeric_cols.fillna(means)\n",
    "\n",
    "\n",
    "\n",
    "## transform both datasetss' categorical NaNs replaced by random category of variable while respecting proportions\n",
    "\n",
    "cat_cols = df_predict.select_dtypes(include=['object'])\n",
    "\n",
    "### for the df_touse or trainset\n",
    "# Iterate over the categorical columns\n",
    "for col_name in cat_cols.columns:\n",
    "    # Select the column\n",
    "    col = df_touse[col_name]\n",
    "    \n",
    "    # Compute the proportions of the categories\n",
    "    counts = col.value_counts(normalize=True)\n",
    "    \n",
    "    # Replace the NaN values with random categories\n",
    "    for i in col.index:\n",
    "        if pd.isnull(col[i]):\n",
    "            col[i] = random.choices(counts.index, counts.values)[0]\n",
    "            \n",
    "df_touse.update(col)\n",
    "\n",
    "### for the df_predict or testset\n",
    "# Iterate over the categorical columns\n",
    "for col_name in cat_cols.columns:\n",
    "    # Select the column\n",
    "    col = df_predict[col_name]\n",
    "    \n",
    "    # Compute the proportions of the categories\n",
    "    counts = col.value_counts(normalize=True)\n",
    "    \n",
    "    # Replace the NaN values with random categories\n",
    "    for i in col.index:\n",
    "        if pd.isnull(col[i]):\n",
    "            col[i] = random.choices(counts.index, counts.values)[0]\n",
    "            \n",
    "df_predict.update(col)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## One Hot Encode categorical variables\n",
    "### for the df_touse or trainset\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "### Select the string columns\n",
    "string_columns = df_touse.select_dtypes(['object']).columns\n",
    "\n",
    "### Create a OneHotEncoder object\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "### Fit the encoder to the string columns\n",
    "encoder.fit(df_touse[string_columns])\n",
    "\n",
    "### Encode the string columns\n",
    "encoded_data = encoder.transform(df_touse[string_columns])\n",
    "\n",
    "### Create a DataFrame with the encoded columns and the original index\n",
    "encoded_df = pd.DataFrame(encoded_data.toarray(), index=df_touse.index, columns=encoder.get_feature_names(string_columns))\n",
    "\n",
    "### Concatenate the encoded columns with the rest of the data\n",
    "df_touse = pd.concat([encoded_df, df_touse.drop(string_columns, axis=1)], axis=1)\n",
    "\n",
    "\n",
    "### for the df_predict or testset\n",
    "\n",
    "### Select the string columns\n",
    "string_columns = df_predict.select_dtypes(['object']).columns\n",
    "\n",
    "### Create a OneHotEncoder object\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "### Fit the encoder to the string columns\n",
    "encoder.fit(df_predict[string_columns])\n",
    "\n",
    "### Encode the string columns\n",
    "encoded_data = encoder.transform(df_predict[string_columns])\n",
    "\n",
    "### Create a DataFrame with the encoded columns and the original index\n",
    "encoded_df = pd.DataFrame(encoded_data.toarray(), index=df_predict.index, columns=encoder.get_feature_names(string_columns))\n",
    "\n",
    "### Concatenate the encoded columns with the rest of the data\n",
    "df_predict = pd.concat([encoded_df, df_predict.drop(string_columns, axis=1)], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train Gradiant Boosting model\n",
    "\n",
    "### Make predictions on the dt_touse or test data\n",
    "Y = df_touse['target']\n",
    "\n",
    "X = df_touse.drop('target', axis=1)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {'learning_rate': [0.2,0.1, 0.05, 0.01]}\n",
    "\n",
    "\n",
    "# Create the gradient boosting model\n",
    "gb = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "# Create the K-fold cross-validation object\n",
    "cv_folds = KFold(5, shuffle=True, random_state=0)\n",
    "\n",
    "# Create the grid search object\n",
    "gb_cv = GridSearchCV(gb, param_grid, cv=cv_folds, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "gb_cv.fit(X, Y)\n",
    "\n",
    "predictions_gb = gb_cv.predict(df_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9196cf08-ba63-45fd-9c44-73abf892e9b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt_predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_31276/1192602326.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PERSON_ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions_gb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dt_predict' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = df_predict['PERSON_ID']\n",
    "predictions = predictions.assign(target=predictions_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b601c28-e682-4bfd-835b-09ab7696479c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
