{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7fd3838-0063-4f94-9458-78a61e3be99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6107efee-ae2e-4b45-a70c-323cea6036c9",
   "metadata": {},
   "source": [
    "## Load dataset and divide dataset in training and testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3180916c-8c36-4471-9a25-5cd2ad4ace19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_touse, df_predict = pickle.load(open('datasets.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5139e96-0f3b-4b13-83e7-7862307b69de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tousebis = df_touse\n",
    "predictors = df_tousebis.columns.tolist()\n",
    "predictors.remove(\"target\")\n",
    "X = df_tousebis[predictors]\n",
    "y = df_tousebis[\"target\"]\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55937874-181f-41ee-9a86-fb09c7b7662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame has NaN values.\n"
     ]
    }
   ],
   "source": [
    "X_train.head(30)\n",
    "has_nan = X_train.isnull().any().any()\n",
    "\n",
    "if has_nan:\n",
    "    print(\"The DataFrame has NaN values.\")\n",
    "else:\n",
    "    print(\"The DataFrame does not have any NaN values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2497ca2a-b2f6-4c65-b3d8-346abf5d53ad",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39ddd510-1d15-4045-8e9c-6b13e07c07d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "var_thr = VarianceThreshold(threshold=10)\n",
    "\n",
    "var_thr.fit_transform(X_train.select_dtypes(include=np.number))\n",
    "\n",
    "var_thr.get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566d6d82-c4f5-4cde-9eb1-26b513c7853f",
   "metadata": {},
   "source": [
    "## Transforming numerical variables NaNs by replacing them with median of variable to perform feature selection on numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "823148a3-6ce6-4c55-9da4-5461d8c93c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the numerical columns\n",
    "numeric_cols = X_train.select_dtypes(include=['int', 'float'])\n",
    "\n",
    "# Compute the median of each numerical column\n",
    "medians = numeric_cols.median()\n",
    "\n",
    "# Replace NaN values with the median of each column\n",
    "X_train[numeric_cols.columns] = numeric_cols.fillna(medians)\n",
    "\n",
    "\n",
    "\n",
    "Y_train = Y_train.to_frame()\n",
    "# Select only the numerical columns\n",
    "numeric_cols = Y_train.select_dtypes(include=['int', 'float'])\n",
    "\n",
    "# Compute the median of each numerical column\n",
    "medians = numeric_cols.median()\n",
    "\n",
    "# Replace NaN values with the median of each column\n",
    "Y_train[numeric_cols.columns] = numeric_cols.fillna(medians)\n",
    "Y_train = Y_train.squeeze()\n",
    "\n",
    "\n",
    "\n",
    "## Same for Y_test\n",
    "\n",
    "Y_test = Y_test.to_frame()\n",
    "# Select only the numerical columns\n",
    "numeric_cols = Y_test.select_dtypes(include=['int', 'float'])\n",
    "\n",
    "# Compute the median of each numerical column\n",
    "medians = numeric_cols.median()\n",
    "\n",
    "# Replace NaN values with the median of each column\n",
    "Y_test[numeric_cols.columns] = numeric_cols.fillna(medians)\n",
    "Y_test = Y_test.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b44e550-de71-40eb-bfed-2690defe4870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame has NaN values.\n"
     ]
    }
   ],
   "source": [
    "has_nan = X_train.isnull().any().any()\n",
    "\n",
    "if has_nan:\n",
    "    print(\"The DataFrame has NaN values.\")\n",
    "else:\n",
    "    print(\"The DataFrame does not have any NaN values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c30cb3ef-8885-490e-8485-ed5f3613eb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 608.14806985, 1407.97038666,  837.1958725 ,   16.78542599]),\n",
       " array([2.81072041e-133, 7.18936557e-303, 3.36041170e-182, 4.19358964e-005]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F_regression\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "\n",
    "numerical_test= SelectKBest(f_regression, k='all')\n",
    "numerical_test.fit_transform(X_train.select_dtypes(include=np.number), Y_train) \n",
    "\n",
    "numerical_test.scores_\n",
    "\n",
    "f_regression(X_train.select_dtypes(include=np.number), Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e54b0b-2a76-4536-b3bf-116d9b1a295f",
   "metadata": {},
   "source": [
    "## Replacing all NaNs of categorical variables to a random assignment of a category by respecting proprtions within the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "346d95e6-96b9-470f-9e83-8418a9e2dc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_28868/3237520104.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_28868/3237520104.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_28868/3237520104.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_28868/3237520104.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_28868/3237520104.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_28868/3237520104.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_28868/3237520104.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_28868/3237520104.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_28868/3237520104.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_28868/3237520104.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_28868/3237520104.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_28868/3237520104.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_28868/3237520104.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_28868/3237520104.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_28868/3237520104.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_28868/3237520104.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_28868/3237520104.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_28868/3237520104.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_28868/3237520104.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n",
      "/var/folders/l6/36kbn2fd34q7z3t8k7r87g8h0000gn/T/ipykernel_28868/3237520104.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = random.choices(counts.index, counts.values)[0]\n"
     ]
    }
   ],
   "source": [
    "## For the training set\n",
    "# Select only the categorical columns\n",
    "cat_cols = X_train.select_dtypes(include=['object'])\n",
    "\n",
    "# Iterate over the categorical columns\n",
    "for col_name in cat_cols.columns:\n",
    "    # Select the column\n",
    "    col = X_train[col_name]\n",
    "    \n",
    "    # Compute the proportions of the categories\n",
    "    counts = col.value_counts(normalize=True)\n",
    "    \n",
    "    # Replace the NaN values with random categories\n",
    "    for i in col.index:\n",
    "        if pd.isnull(col[i]):\n",
    "            col[i] = random.choices(counts.index, counts.values)[0]\n",
    "            \n",
    "X_train.update(col)\n",
    "\n",
    "\n",
    "\n",
    "## For the test set\n",
    "\n",
    "cat_cols = X_test.select_dtypes(include=['object'])\n",
    "\n",
    "# Iterate over the categorical columns\n",
    "for col_name in cat_cols.columns:\n",
    "    # Select the column\n",
    "    col = X_test[col_name]\n",
    "    \n",
    "    # Compute the proportions of the categories\n",
    "    counts = col.value_counts(normalize=True)\n",
    "    \n",
    "    # Replace the NaN values with random categories\n",
    "    for i in col.index:\n",
    "        if pd.isnull(col[i]):\n",
    "            col[i] = random.choices(counts.index, counts.values)[0]\n",
    "            \n",
    "X_test.update(col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf2f0b2-ccac-479a-b12f-a5c63f466977",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71537d8c-5d80-4f01-a037-02531f8933bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "has_nan = X_train.isnull().any().any()\n",
    "\n",
    "if has_nan:\n",
    "    print(\"The DataFrame has NaN values.\")\n",
    "else:\n",
    "    print(\"The DataFrame does not have any NaN values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebcb4c4-ad8a-4f8d-bff3-0c9b93cdcc97",
   "metadata": {},
   "source": [
    "## OneHotencode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873297ad-0420-41af-973f-19a06a141c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import not to create hot codes for this\n",
    "X_train = X_train.drop(columns=['insee'])\n",
    "X_test = X_test.drop(columns=['insee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368b9308-27a7-4c46-ac3b-2499a0eb379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "## For the Train set\n",
    "\n",
    "# Select the string columns\n",
    "string_columns = X_train.select_dtypes(['object']).columns\n",
    "\n",
    "# Create a OneHotEncoder object\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit the encoder to the string columns\n",
    "encoder.fit(X_train[string_columns])\n",
    "\n",
    "# Encode the string columns\n",
    "encoded_data = encoder.transform(X_train[string_columns])\n",
    "\n",
    "# Create a DataFrame with the encoded columns and the original index\n",
    "encoded_df = pd.DataFrame(encoded_data.toarray(), index=X_train.index, columns=encoder.get_feature_names(string_columns))\n",
    "\n",
    "# Concatenate the encoded columns with the rest of the data\n",
    "X_train = pd.concat([encoded_df, X_train.drop(string_columns, axis=1)], axis=1)\n",
    "\n",
    "\n",
    "## For the Test set\n",
    "\n",
    "# Select the string columns\n",
    "string_columns = X_test.select_dtypes(['object']).columns\n",
    "\n",
    "# Create a OneHotEncoder object\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit the encoder to the string columns\n",
    "encoder.fit(_test[string_columns])\n",
    "\n",
    "# Encode the string columns\n",
    "encoded_data = encoder.transform(_test[string_columns])\n",
    "\n",
    "# Create a DataFrame with the encoded columns and the original index\n",
    "encoded_df = pd.DataFrame(encoded_data.toarray(), index=_test.index, columns=encoder.get_feature_names(string_columns))\n",
    "\n",
    "# Concatenate the encoded columns with the rest of the data\n",
    "X_test = pd.concat([encoded_df, X_test.drop(string_columns, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcf0e49-f7bd-4b87-a2fb-a9dc85a68ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_nan = X_train.isnull().any().any()\n",
    "\n",
    "if has_nan:\n",
    "    print(\"The DataFrame has NaN values.\")\n",
    "else:\n",
    "    print(\"The DataFrame does not have any NaN values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773878bf-dc24-42f7-8e47-177c434d6660",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3219d6f3-b1f0-489d-ad5b-1c692e187dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcdf264-3a4d-4963-891f-13a4b36b0650",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6224a-e1c3-4ee7-a7ed-7bd2ac614f9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f3c8c4-37c2-4559-b920-9a81f25f3906",
   "metadata": {},
   "source": [
    "## DecisionTree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e125d18f-d200-4b7b-873e-d8b39c09677b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "dt_params = {'min_samples_split': [2, 5] + list(range(10, 100, 5))}\n",
    "\n",
    "#,\n",
    "#              'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "#              'min_impurity_decrease': [0.0, 0.1, 0.2, 0.3]}\n",
    "\n",
    "\n",
    "#dt_params = {'min_samples_split': [2, 5] + list(range(10, 250,5))} \n",
    "dt = DecisionTreeRegressor(random_state=0)\n",
    "cv_folds = KFold(5, shuffle=True, random_state=0)\n",
    "dt_cv = GridSearchCV(dt, dt_params, cv=cv_folds, n_jobs=-1) \n",
    "dt_cv.fit(X_train, Y_train) \n",
    "print(dt_cv.best_score_)\n",
    "print(dt_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c71fe4a-760b-406c-a733-a06ba6e2ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import math\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = dt_cv.predict(X_test)\n",
    "\n",
    "# Compute the mean absolute error\n",
    "mae = mean_absolute_error(Y_test, predictions)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(Y_test, predictions)\n",
    "\n",
    "# Compute the root mean squared error\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "# Compute the R-squared score\n",
    "r2 = r2_score(Y_test, predictions)\n",
    "\n",
    "# Compute the adjusted R-squared score\n",
    "n = len(Y_test)\n",
    "p = X_test.shape[1]  # number of features\n",
    "adj_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Mean absolute error: {:.2f}\".format(mae))\n",
    "print(\"Mean squared error: {:.2f}\".format(mse))\n",
    "print(\"Root mean squared error: {:.2f}\".format(rmse))\n",
    "print(\"R-squared score: {:.2f}\".format(r2))\n",
    "print(\"Adjusted R-squared score: {:.2f}\".format(adj_r2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051a2ed4-8360-480b-ac6f-b18afad17297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "321b04ba-82bc-4f6c-80e2-789e628f17b5",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8243464c-0d09-4797-bd32-7867f6244632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {'learning_rate': [0.2]}\n",
    "#                                0.05, 0.01, 0.005, 0.001]}\n",
    "\n",
    "\n",
    "# Create the gradient boosting model\n",
    "gb = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "# Create the K-fold cross-validation object\n",
    "cv_folds = KFold(5, shuffle=True, random_state=0)\n",
    "\n",
    "# Create the grid search object\n",
    "gb_cv = GridSearchCV(gb, param_grid, cv=cv_folds, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "gb_cv.fit(X_train, Y_train)\n",
    "\n",
    "print(gb_cv.best_score_)\n",
    "print(gb_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b0ab60-1287-4cd5-9128-4ce79f170cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = gb_cv.predict(X_test)\n",
    "\n",
    "# Compute the mean absolute error\n",
    "mae = mean_absolute_error(Y_test, predictions)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(Y_test, predictions)\n",
    "\n",
    "# Compute the root mean squared error\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "# Compute the R-squared score\n",
    "r2 = r2_score(Y_test, predictions)\n",
    "\n",
    "# Compute the adjusted R-squared score\n",
    "n = len(Y_test)\n",
    "p = X_test.shape[1]  # number of features\n",
    "adj_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Mean absolute error: {:.2f}\".format(mae))\n",
    "print(\"Mean squared error: {:.2f}\".format(mse))\n",
    "print(\"Root mean squared error: {:.2f}\".format(rmse))\n",
    "print(\"R-squared score: {:.2f}\".format(r2))\n",
    "print(\"Adjusted R-squared score: {:.2f}\".format(adj_r2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826b3205-c01f-434a-9768-2888f49fa259",
   "metadata": {},
   "source": [
    "## Ridge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa3587c-b964-452a-bf49-5ba090d03377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {'alpha': [0.1, 1.0, 10.0, 100.0, 1000.0],\n",
    "              'max_iter': [100, 1000, 10000, 100000]}\n",
    "\n",
    "# Create the ridge regression model\n",
    "ridge = Ridge(random_state=0)\n",
    "\n",
    "# Create the K-fold cross-validation object\n",
    "cv_folds = KFold(5, shuffle=True, random_state=0)\n",
    "\n",
    "# Create the grid search object\n",
    "ridge_cv = GridSearchCV(ridge, param_grid, cv=cv_folds, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "ridge_cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc0207b-20e5-4a85-9a56-a4fc3a6eee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ridge_cv.best_score_)\n",
    "print(ridge_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff27479d-baff-4ece-a0be-ec32844f631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import math\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = ridge_cv.predict(X_test)\n",
    "\n",
    "# Compute the mean absolute error\n",
    "mae = mean_absolute_error(Y_test, predictions)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(Y_test, predictions)\n",
    "\n",
    "# Compute the root mean squared error\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "# Compute the R-squared score\n",
    "r2 = r2_score(Y_test, predictions)\n",
    "\n",
    "# Compute the adjusted R-squared score\n",
    "n = len(Y_test)\n",
    "p = X_test.shape[1]  # number of features\n",
    "adj_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Mean absolute error: {:.2f}\".format(mae))\n",
    "print(\"Mean squared error: {:.2f}\".format(mse))\n",
    "print(\"Root mean squared error: {:.2f}\".format(rmse))\n",
    "print(\"R-squared score: {:.2f}\".format(r2))\n",
    "print(\"Adjusted R-squared score: {:.2f}\".format(adj_r2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc8ac39-c3a3-4102-83b8-aa374b854e2c",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab8b187-6314-412f-94ce-4dd2a8818d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {'n_estimators': [50, 100, 200, 300, 400, 500],\n",
    "              'max_depth': [2, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "              'min_samples_split': [2, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "              'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "\n",
    "# Create the random forest model\n",
    "rf = RandomForestRegressor(random_state=0)\n",
    "\n",
    "# Create the K-fold cross-validation object\n",
    "cv_folds = KFold(5, shuffle=True, random_state=0)\n",
    "\n",
    "# Create the grid search object\n",
    "rf_cv = GridSearchCV(rf, param_grid, cv=cv_folds, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "rf_cv.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc36d6db-0e0c-40a0-b7ed-9d2955aa0783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import math\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = rf_cv.predict(X_test)\n",
    "\n",
    "# Compute the mean absolute error\n",
    "mae = mean_absolute_error(Y_test, predictions)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(Y_test, predictions)\n",
    "\n",
    "# Compute the root mean squared error\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "# Compute the R-squared score\n",
    "r2 = r2_score(Y_test, predictions)\n",
    "\n",
    "# Compute the adjusted R-squared score\n",
    "n = len(Y_test)\n",
    "p = X_test.shape[1]  # number of features\n",
    "adj_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Mean absolute error: {:.2f}\".format(mae))\n",
    "print(\"Mean squared error: {:.2f}\".format(mse))\n",
    "print(\"Root mean squared error: {:.2f}\".format(rmse))\n",
    "print(\"R-squared score: {:.2f}\".format(r2))\n",
    "print(\"Adjusted R-squared score: {:.2f}\".format(adj_r2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be21d9a0-71bb-407d-9816-e1f42b8ecaf5",
   "metadata": {},
   "source": [
    "## LASSO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
